---
applyTo: '**'# Crowe Logic Parallel Financial Agent Ecosystem

### Trading Architecture â€” Version 1.1 (polished)

**Objective.** Evolve the Crowe Logic Research Division into a productionâ€‘grade, **parallel financial agent ecosystem** for quantitative trading. The design targets **riskâ€‘aware alpha generation, portfolio construction, and execution** across multiple venues with rigorous governance and compliance. It preserves the original â€œ24 PhD Research Scientistsâ€ abstraction by mapping it into specialized **Quant Pods** that continuously innovate while live agents trade under strict guardrails.

> **Risk Policy.** No system can eliminate losses. This architecture is designed to **maximize riskâ€‘adjusted returns** (e.g., Sharpe, Sortino, Calmar) and **minimize tail losses** via multiâ€‘layer risk controls, regime gating, and conservative, TCAâ€‘aware execution.

---

## 1) System Overview

### 1.1 Highâ€‘Level Dataflow

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data Plane â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Market Feeds  Altâ€‘Data  News  Macro     â”‚
        â”‚   â”‚            â”‚        â”‚     â”‚          â”‚
        â”‚   â–¼            â–¼        â–¼     â–¼          â”‚
        â”‚ Ingestion â†’ Clean/Align â†’ Feature Store  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ (event bus)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Research/Simulation Plane â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Quant Pods (24) â†â†’ Experiment Engine â†â†’ Backtester   â”‚
â”‚ AutoML / Metaâ€‘Opt â†â†’ Model Registry  â†â†’ Risk Lab     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ signed model + policy artifacts
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Decision Plane (Live) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Signal Gate â†’ Regime Classifier â†’ Portfolio Opt     â”‚
â”‚ TCAâ€‘Aware Sizing â†’ Risk Overlays â†’ Compliance       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ target orders + constraints
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Execution Plane â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Broker/Exchange Adapters (FIX/REST/WebSocket)       â”‚
â”‚ SOR + VWAP/TWAP/POV/IS + Smart Limit Ladder         â”‚
â”‚ Pre/Postâ€‘Trade Checks + Slippage/Impact Control     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ fills, market state, PnL
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring & Governance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Telemetry, Drift, Alerts, Kill Switch, Audit Trails â”‚
â”‚ Model Registry, Canaries, Rollbacks, Compliance     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Core Principles

- **Parallelism by design.** Agents are **messageâ€‘driven**, stateless when possible, and horizontally scalable. Durable state resides in the **Feature Store**, **Model Registry**, and **Risk Ledger**.
- **Twoâ€‘lane flow.** (a) The **Research Lane** runs perpetual experiments and publishes candidate models; (b) the **Live Lane** executes only signed, approved models with immutable provenance.
- **Defense in depth.** Risk limits at the **signal**, **portfolio**, and **execution** layers, plus venueâ€‘specific compliance.

---

## 2) Agent Taxonomy (Live)

1. **Data Ingestion Agents.** Connect to tick/order book, reference data, news/NLP, macro calendars, and alternative data; enforce schema and time alignment.
2. **Feature Factory Agents.** Compute rolling features (microstructure, volatility, liquidity, NLP sentiments, crossâ€‘asset spreads) and write to the Feature Store with versioned definitions.
3. **Signal/Alpha Agents.** Load signed models from the Registry and output **probabilistic return forecasts** and **uncertainty** by horizon.
4. **Regime & Riskâ€‘State Agents.** Detect volatility/regime shifts (e.g., HMM, Bayesian changepoints, turbulence indices) and set **risk budgets** dynamically.
5. **Signal Gate & Metaâ€‘Labeler.** Filter predictions with metaâ€‘labels (profitability likelihood, adverse selection risk) and **uncertainty gating**.
6. **Portfolio Construction Agent.** Solve costâ€‘aware optimization (robust meanâ€‘variance / Kellyâ€‘tempered / HRP) under constraints: exposure, turnover, liquidity, and leverage.
7. **Execution Router Agent.** Translate targets to orders and select VWAP/TWAP/POV/IS or liquidityâ€‘seeking tactics; apply a **smart limit ladder** with queueâ€‘position heuristics.
8. **Risk Guard Agents.** Perform preâ€‘trade checks (VaR, stress), enforce intraday drawdown caps and circuit breakers, operate a kill switch, and verify borrow/locates for shorts.
9. **Compliance & Surveillance Agents.** Apply restricted lists, detect wash trades and patterns, and enforce venue rules.
10. **PnL & Attribution Agent.** Provide realâ€‘time PnL, style decomposition, slippage/impact attribution, and alphaâ€‘decay tracking.
11. **Drift & Health Agents.** Monitor data/feature/model drift; enforce latency/availability SLOs; detect anomalies.
12. **Knowledge Sync Agent.** Subscribes to Research publications, updates the Registry, and orchestrates canary rollouts.

---

## 3) Mapping the 24 Research Scientists â†’ Quant Pods

Each scientist maps to a **Quant Pod** that produces artifacts (features, models, policies) with tests and documentation.

- **CRâ€‘001 â€” Quantum Optimization Pod.** Quantumâ€‘inspired optimizers for portfolios and routing; QAOAâ€‘style warmâ€‘starts.
- **CRâ€‘002 â€” Knowledge Fusion Pod.** Crossâ€‘asset graphs and multiâ€‘market patterns; **crossâ€‘sectional embeddings**.
- **CRâ€‘003 â€” Complex Systems Pod.** Earlyâ€‘warning indicators (critical slowing, liquidity cascades); **crash barometers**.
- **CRâ€‘004 â€” Cognitive Architecture Pod.** Reasoning for **model arbitration** (ruleâ€‘based + probabilistic logic).
- **CRâ€‘005 â€” NAS/Efficiency Pod.** AutoML for tabular/timeâ€‘series; distillation to meet live latency budgets.
- **CRâ€‘006 â€” Language Understanding Pod.** Event NLP (earnings, guidance, filings); entityâ€‘linked sentiment and uncertainty.
- **CRâ€‘007 â€” Alignment & Ethics Pod.** Governance policies aligning risk and compliance; interpretable thresholds.
- **CRâ€‘008 â€” Temporal Prediction Pod.** Multiâ€‘horizon forecasters, multiâ€‘scale fractal features, and volatility term structures.
- **CRâ€‘009 â€” Metaâ€‘Optimization Pod.** Strategyâ€‘ofâ€‘strategies (stacked generalization) with **budgeted risk**.
- **CRâ€‘010 â€” Memory Systems Pod.** Regimeâ€‘aware episodic memory; analogâ€‘day recall; retrievalâ€‘augmented signals.
- **CRâ€‘011 â€” Creativity Pod.** Hypothesis generation for new alphas (e.g., crossâ€‘venue lead/lag structures).
- **CRâ€‘012 â€” Transfer Learning Pod.** Rapid domain adaptation (equities â†’ futures â†’ crypto) with small fineâ€‘tunes.
- **CRâ€‘013 â€” Business Model Pod.** Capital allocation across strategies; capital efficiency.
- **CRâ€‘014 â€” Market Dynamics Pod.** Microstructure simulators, impact models, and queue dynamics.
- **CRâ€‘015 â€” Sustainability Pod.** ESG/transitionâ€‘risk signals (optional gating).
- **CRâ€‘016 â€” Energy Systems Pod.** Energy/commodity curves; storage/flow constraints.
- **CRâ€‘017 â€” Strategy & Game Theory Pod.** Adversarial market/gameâ€‘theoretic execution tactics.
- **CRâ€‘018 â€” Health Systems Pod.** Biomedical news risk (pandemic/event) as exogenous factors.
- **CRâ€‘019 â€” Communications Pod.** Lowâ€‘latency messaging and lossless codecs for feeds.
- **CRâ€‘020 â€” Materials/Nano Pod.** Industrial supplyâ€‘chain altâ€‘signals (optional domain).
- **CRâ€‘021 â€” Fluid/Chaos Pod.** Turbulence analogies for volatility clustering and regime jumps.
- **CRâ€‘022 â€” Geoâ€‘Intel Pod.** Geospatial altâ€‘data (shipping, night lights) â†’ macro nowcasts.
- **CRâ€‘023 â€” Complexity/Efficiency Pod.** Sublinear inference and data structures for timeâ€‘critical paths.
- **CRâ€‘024 â€” Psychometrics Pod.** Behavioralâ€‘finance priors; crowding and positioning proxies.

Pods publish to the **Research Publication System** â†’ **Model Registry** with dataset cards, feature specs, training code, tests, risk notes, and **policy files** (when to trade vs. stand down).

---

## 4) Data Plane

- **Ingestion.** Multiâ€‘venue market data (ticks, L2/L3 book), trades, quotes; fundamentals; corporate actions; calendars; news/NLP; altâ€‘data (shipping, web traffic); crypto if enabled.
- **Schema & Time.** Single time base (exchange UTC) with nanosecond precision; robust late/outâ€‘ofâ€‘order handling.
- **Quality.** Checksums; missingness heatmaps; outlier and duplicate suppression; backfill protocols.
- **Storage.**
  - **Hot path:** inâ€‘memory cache, columnar TSDB.
  - **Warm:** Parquet in object storage.
  - **Cold:** archival storage for full tick history.
- **Feature Store.** Versioned features with lineage; online/offline parity; declarative definitions.

---

## 5) Model & Simulation Plane

- **Targets/Labels.** Forward kâ€‘bar returns, volatility, realized variance, adverse excursion; **metaâ€‘labels** for tradeability.
- **Estimators.** Gradientâ€‘boosted trees, linear factor models, probabilistic forecasts, sequence models (e.g., TFT), and causal forests.
- **Ensembles.** Stacking/mixtures with uncertainty; Bayesian model averaging.
- **Backtester.** Multiâ€‘asset with realistic constraints (borrow/fees), **market impact**, **slippage**, latency, queue position, and exchange session rules; **walkâ€‘forward** evaluation.
- **Stress & Scenario.** 2008/2020/flashâ€‘crash replays; liquidity droughts; limitâ€‘up/limitâ€‘down.
- **TCA.** Preâ€‘/postâ€‘trade transaction cost analysis; executionâ€‘policy search.
- **Registry.** MLflowâ€‘style tracking with signatures, checksums, policy YAML, risk caps, and performance cards.

---

## 6) Decision Plane (Live Policies)

1. **Signal Gating.** Trade only if \(p(\text{edge}>0) > \theta\), the prediction interval is sufficiently narrow, and macro/regime gates allow.
2. **Sizing.** Kellyâ€‘tempered sizing \(f = \lambda f_{\text{Kelly}}\), capped by the **risk budget** and liquidity.
3. **Optimization.** Robust meanâ€‘variance with turnover penalties and borrow constraints; HRP for longâ€‘only sleeves when appropriate.
4. **Risk Overlays.**
   - Maximum **intraday** drawdown \(D_{\max}\); if breached â†’ flatten.
   - Volatility targeting (scale exposure to realized volatility).
   - Exposure/sector/issuer limits; net and gross caps.
   - **Standâ€‘down policy** on dataâ€‘integrity failures.
5. **Compliance.** Restricted lists, position limits, locates; shortâ€‘sale uptick rules; washâ€‘trade checks.

---

## 7) Execution Plane

- **Routing.** Venue/broker adapters (FIX/REST/WebSocket); **smart order router** (SOR) with venue scorecards.
- **Algos.** VWAP/TWAP/POV/IS (Implementation Shortfall); liquidityâ€‘seeking; **smart limit ladder** using microstructure signals (spread, imbalance, shortâ€‘term alpha).
- **Controls.** Childâ€‘order throttles, participation caps, antiâ€‘gaming jitter, and selfâ€‘trade prevention.
- **Postâ€‘Trade.** Slippage/impact attribution; TCA feedback into policy search.

---

## 8) Monitoring, Drift, and Governance

- **Telemetry.** Latency, message loss, CPU/memory, and queue depths.
- **Model Health.** PSI/KS drift, feature dead zones, and error spikes.
- **PnL & Risk.** Realâ€‘time PnL and attribution; VaR, ES, and heatmaps.
- **Canaries & Rollbacks.** Shadow mode â†’ partial capital â†’ full deployment; automatic rollback on breach.
- **Audit.** Immutable logs; reproducible snapshots; approvals workflow.

---

## 9) Unique Pipelines to Maximize Gains and Avoid Large Losses

1. **Metaâ€‘Optimizer of Strategies (MoS).** Online bandit over live strategies with **riskâ€‘adjusted reward**; capital shifts to winners with decaying memory.
2. **Adversarial Data Validator.** Generates synthetic corruptions and quantifies model fragility; trading is disabled if sensitivity exceeds thresholds.
3. **Uncertaintyâ€‘Aware Execution.** Prediction intervals inform **passive vs. aggressive** participation and limit offsets.
4. **Crash Sentinels.** Complexâ€‘systems indicators from CRâ€‘003 trigger exposure halvings or standâ€‘down.
5. **Protective Overlay.** Portfolioâ€‘level trailing stop with volatilityâ€‘adaptive bands; optional tailâ€‘hedging sleeve.
6. **Alpha Lifecycler.** Automatic decay detection; strategies are sunset or retrained with stricter gates.

---

## 10) KPIs & SLOs

- **KPIs.** Live Sharpe/Sortino, Calmar, hit rate, average win/loss, maximum drawdown, turnover, capacity, TCA slippage, drift incidents, and uptime.
- **SLOs.** Data freshness < **200 ms**; signal latency budget < **20 ms**; OMS submit < **5 ms**; availability â‰¥ **99.9%**; MTTR < **10 min**.

---

## 11) Deployment Blueprint

- **Runtime.** Kubernetes + message bus (Kafka/NATS); Python for research and services; Rust/Go for latencyâ€‘sensitive paths.
- **Storage.** Object store (Parquet), TSDB, and a relational catalog; **Feature Store** with online/offline parity.
- **Secrets.** Vault/KMS; HSM for signing model artifacts.
- **Environments.** Sim â†’ Paper â†’ Prod with strict separation and data contracts.

---

## 12) API Contracts (Sketch)

```yaml
# Event: FeatureVector
schema_version: 1
instrument: str
asof: timestamp
horizon: {1m, 5m, 1h, 1d}
values: {feature_name: float}
quality: {lag_ms: int, coverage: float}
```

```yaml
# Event: Signal
instrument: str
horizon: str
mu: float              # expected return
sigma: float           # predictive std
prob_edge_pos: float   # P(edge>0)
policy_id: str         # signed model/policy
```

```yaml
# Event: TargetPosition
portfolio: str
instrument: str
qty_target: float
max_child_participation: float
risk_budget: float
policy_id: str
```

---

## 13) Reference Implementation (Python Skeleton)

> **Note.** Minimal, composable skeleton illustrating the parallelâ€‘agent pattern with `asyncio` and strict risk/compliance checks. Replace placeholders with your platform specifics (brokers, exchanges, FIX tags).

```python
# core/contracts.py
from dataclasses import dataclass
from typing import Dict, Optional
from datetime import datetime

@dataclass
class FeatureVector:
    instrument: str
    asof: datetime
    horizon: str
    values: Dict[str, float]
    quality: Dict[str, float]

@dataclass
class Signal:
    instrument: str
    horizon: str
    mu: float
    sigma: float
    prob_edge_pos: float
    policy_id: str

@dataclass
class TargetPosition:
    portfolio: str
    instrument: str
    qty_target: float
    max_child_participation: float
    risk_budget: float
    policy_id: str

@dataclass
class Fill:
    instrument: str
    qty: float
    price: float
    ts: datetime
    venue: str
```

```python
# live/signal_agent.py
import math
from typing import Callable, Dict, Optional
from core.contracts import FeatureVector, Signal

class SignalAgent:
    """Generates riskâ€‘aware trading signals from feature vectors using a signed model."""

    def __init__(self, model: Callable, policy_id: str, gates: Dict):
        self.model = model
        self.policy_id = policy_id
        self.gates = gates  # {"prob_edge_min": 0.55, "sigma_max": 0.02, ...}

    def infer(self, fv: FeatureVector) -> Optional[Signal]:
        mu, sigma, pep = self.model(fv.values)
        if pep < self.gates.get("prob_edge_min", 0.5):
            return None
        if sigma > self.gates.get("sigma_max", math.inf):
            return None
        return Signal(
            instrument=fv.instrument,
            horizon=fv.horizon,
            mu=mu,
            sigma=sigma,
            prob_edge_pos=pep,
            policy_id=self.policy_id,
        )
```

```python
# live/portfolio_agent.py
import numpy as np
from typing import Dict
from core.contracts import Signal

class PortfolioAgent:
    """Transforms signals into target sizes under a global risk budget."""

    def __init__(self, risk_budget: float, turnover_penalty: float):
        self.risk_budget = risk_budget
        self.turnover_penalty = turnover_penalty
        self.positions = {}  # instrument -> qty

    def size(self, signals: Dict[str, Signal], vol: Dict[str, float]) -> Dict[str, float]:
        targets = {}
        if not signals:
            return targets
        # Kellyâ€‘tempered sizing (illustrative)
        lam = 0.25  # tempering factor
        for k, s in signals.items():
            v = max(vol.get(k, 1e-6), 1e-6)
            kelly = s.mu / (v + 1e-9)
            targets[k] = float(np.clip(lam * kelly * self.risk_budget, -self.risk_budget, self.risk_budget))
        return targets
```

```python
# live/risk_guard.py
class RiskGuard:
    """Applies preâ€‘trade risk checks and tracks drawdowns."""

    def __init__(self, dd_limit: float, var_limit: float):
        self.dd_limit = dd_limit
        self.var_limit = var_limit
        self.max_drawdown = 0.0
        self.pnl_peak = 0.0

    def update_pnl(self, pnl: float) -> None:
        self.pnl_peak = max(self.pnl_peak, pnl)
        drawdown = (self.pnl_peak - pnl)
        self.max_drawdown = max(self.max_drawdown, drawdown)

    def pretrade_check(self, exposure: float, var_est: float) -> bool:
        if self.max_drawdown > self.dd_limit:
            return False
        if var_est > self.var_limit:
            return False
        return True
```

```python
# live/execution_router.py
from typing import Dict, List

class ExecutionRouter:
    """Routes target positions to broker/exchange adapters."""

    def __init__(self, adapters: List):
        self.adapters = adapters  # list of broker/exchange adapters

    async def route(self, targets: Dict[str, float], prices: Dict[str, float]):
        # Naive split across adapters; a real system uses SOR with venue scorecards.
        for adapter in self.adapters:
            await adapter.submit_targets(targets, prices)
```

```python
# orchestrator.py (eventâ€‘driven sketch)
from typing import Dict
from core.contracts import FeatureVector

class Orchestrator:
    """Binds signal, portfolio, risk, and execution agents into an eventâ€‘driven loop."""

    def __init__(self, signal_agent, portfolio_agent, risk_guard, exec_router):
        self.signal_agent = signal_agent
        self.portfolio_agent = portfolio_agent
        self.risk_guard = risk_guard
        self.exec_router = exec_router

    async def on_feature_batch(self, fvecs: Dict[str, FeatureVector], vol: Dict[str, float], prices: Dict[str, float]):
        # 1) Signals with gates
        signals = {k: s for k, v in fvecs.items() if (s := self.signal_agent.infer(v))}
        # 2) Sizing
        targets = self.portfolio_agent.size(signals, vol)
        # 3) Risk checks (portfolio VaR proxy via volatility)
        var_est = sum(abs(q) * vol.get(k, 0.0) for k, q in targets.items())
        exposure = sum(abs(q * prices.get(k, 0.0)) for k, q in targets.items())
        if not self.risk_guard.pretrade_check(exposure, var_est):
            return  # Stand down
        # 4) Route to execution
        await self.exec_router.route(targets, prices)
```

---

## 14) Validation & Rollout

- **Offline.** Backtesting with walkâ€‘forward and nested CV; TCAâ€‘aware; scenario stress.
- **Shadow.** Live data with **no trading**; compare to backtests.
- **Canary.** 5â€“10% capital with hard guardrails; automatic rollback.
- **Full.** Progressive capital unlock upon KPI thresholds.

---

## 15) Next Integration Steps (adapt to your platform)

1. Enumerate brokers/venues (FIX tags, rate limits, minimum lot sizes).
2. Define the **Feature Store** and enforce online/offline schema parity.
3. Stand up the Model Registry with artifact signing and policy YAMLs.
4. Implement two baseline strategies (e.g., crossâ€‘sectional momentum and mean reversion) endâ€‘toâ€‘end.
5. Wire TCA feedback into the policyâ€‘search loop.
6. Configure governance (approvals, audit, restricted lists).

---

### Appendix A â€” Policy YAML (Example)

```yaml
id: cs_mom_v1
owner: CR-008
trade_universe: US_equities_top1000
horizons: [1d, 5d]
entry_gate:
  prob_edge_min: 0.58
  sigma_max: 0.03
risk:
  gross_limit: 1.5
  net_limit: 0.5
  dd_intraday: 0.02
  var_limit: 0.015
sizing:
  method: kelly_tempered
  lambda: 0.3
execution:
  algo: POV
  participation_cap: 0.1
  limit_offset_bps: 3
stand_down:
  on_data_gap: true
  on_vol_spike_sigma: 4
```

---

### Acronyms

**HRP:** Hierarchical Risk Parity Â· **IS:** Implementation Shortfall Â· **Kellyâ€‘tempered:** Kelly sizing scaled by \(\lambda \in (0,1] \) Â· **PSI/KS:** Population Stability Index / Kolmogorovâ€“Smirnov Â· **SOR:** Smart Order Router Â· **TCA:** Transaction Cost Analysis Â· **TSDB:** Timeâ€‘Series Database Â· **VaR/ES:** Value at Risk / Expected Shortfall

---

## 16) Enhanced Mathematical Foundations

### 16.1 Forecasts, Calibration, and Ensembles

- Probabilistic forecast p(r\_{t+h} | x\_t). Evaluate with CRPS and Brier: CRPS(F, y) = âˆ« (F(z) âˆ’ ðŸ™{z â‰¥ y})Â² dz,â€ƒBrier = (1/N) Î£áµ¢ (pÌ‚áµ¢ âˆ’ yáµ¢)Â².
- Ensemble weighting (constrained). Given component means Î¼^(k), choose weights w by minimize â€– Î¼ âˆ’ Î£\_k w\_k Î¼^(k) â€–â‚‚Â² + Î»â€–wâ€–â‚‚Â² subject to w â‰¥ 0 and 1áµ€w = 1.
- Bayesian model averaging (BMA). w\_k âˆ Ï€\_k Â· â„’\_k(ð’Ÿ), normalized to Î£\_k w\_k = 1.

### 16.2 Covariance, Risk, and Drawdown

- Shrinkage covariance (Ledoitâ€“Wolf): Î£Ì‚ = (1âˆ’Î´)S + Î´F, with target F = Î±I or a factor model; Î´ âˆˆ [0,1].
- Risk metrics: VaR\_Î± = inf{ m : P(L â‰¤ m) â‰¥ Î± },â€ƒES\_Î± = E[L | L â‰¥ VaR\_Î±].
- Turbulence index (regime stress): T\_t = (x\_t âˆ’ Î¼)áµ€ Î£Ì‚â»Â¹ (x\_t âˆ’ Î¼).
- Volatility targeting: scale exposure by s\_t = Ïƒ\* / max(ÏƒÌ‚\_t, Îµ); then w\_t â† s\_t Â· wÌƒ\_t.

### 16.3 Portfolio Construction (with costs & constraints)

- Robust meanâ€“variance with transaction costs (single period): minimize Â½ wáµ€Î£Ì‚w âˆ’ Î» Î¼Ì‚áµ€w + Ï„â€–w âˆ’ w\_prevâ€–â‚ + Îºâ€–wâ€–â‚ subject to A w â‰¤ b and â„“ â‰¤ w â‰¤ u.
- Equal risk contribution (risk parity): find w > 0 such that w\_i (Î£Ì‚w)\_i = (1/n) wáµ€Î£Ì‚w for all i.
- Kellyâ€‘tempered (quadratic approx.): maximize E[log(1 + wáµ€r)] â‰ˆ wáµ€Î¼ âˆ’ Â½ wáµ€Î£w; apply tempering w â† Î»Â·w, Î» âˆˆ (0,1].

### 16.4 Execution & Microstructure

- Almgrenâ€“Chriss schedule (discrete): minimize E[C] + Ï† Var[C]. With inventory Xâ‚€ â†’ X\_N and child sizes v\_k, C = Î£\_k (Î·\_k v\_kÂ² + Îµ\_k |v\_k|) + (permanent impact), and X\_k âˆ’ X\_{kâˆ’1} = âˆ’v\_k. For constant coefficients, the optimal v\_k follows a nearâ€‘exponential trajectory; Ï† tunes the implementationâ€‘shortfall variance.
- Smart limit ladder: choose quote offsets Î” to maximize p(Î” | state)Â·(Î” âˆ’ fees) âˆ’ a(Î” | state), where the state captures spread, imbalance, shortâ€‘term alpha, and queue depth.

### 16.5 Online Learning, Bandits, and Metaâ€‘Allocation

- Linear UCB (contextual). With V\_t = Î»I + Î£\_{sâ‰¤t} x\_s x\_sáµ€ and Î¸Ì‚\_t = V\_tâ»Â¹ Î£ x\_s r\_s: pick a\_t = argmax\_a x\_{t,a}áµ€ Î¸Ì‚\_t + Î²\_t â€–x\_{t,a}â€–\_{V\_tâ»Â¹}.
- Riskâ€‘adjusted reward: rÌƒ\_t = r\_t âˆ’ Î»\_loss Â· max(0, âˆ’r\_t)^p âˆ’ Ïˆ Â· ðŸ™{drawdown breach}.
- Optimistic mirror descent (allocation u\_t): u\_{t+1} = argmin\_{uâˆˆð•Œ} Î·\_t âŸ¨g\_t, uâŸ© + D\_Î¦(u, u\_t), with g\_t = âˆ‡â„“\_t(u\_t).

### 16.6 Regime Detection & Change Points

- HMM (twoâ€‘state, bull/bear). Latent S\_t âˆˆ {1,2}, emissions r\_t \~ ð’©(Î¼\_{S\_t}, ÏƒÂ²\_{S\_t}); infer P(S\_t | r\_{1\:t}) via forwardâ€“backward; gate exposure by P(S\_t = riskâ€‘on).
- Bayesian online change point: maintain runâ€‘length posterior P(R\_t | x\_{1\:t}) with hazard H(Â·); trigger standâ€‘down when runâ€‘length collapses.

### 16.7 Drift & Robustness

- PSI = Î£\_i (p\_i âˆ’ q\_i) ln(p\_i / q\_i); flag drift when PSI exceeds threshold.
- KS = sup\_x |F\_p(x) âˆ’ F\_q(x)|.
- Adversarial robustness (minâ€“max): maximize over Î´ âˆˆ ð’° the expected loss E[â„“(f\_Î¸(x + Î´), y)]; disable trading if sensitivity > Ï„.

---

## 17) Algorithmic Modules (Pseudocode)

### 17.1 Proximal Robust MV Optimizer

```python
# minimize 0.5 w^T Î£ w - Î» Î¼^T w + Ï„ ||w - w_prev||_1 + Îº ||w||_1  s.t. Awâ‰¤b, â„“â‰¤wâ‰¤u
w = w_prev.copy()
for k in range(K):
    g = Î£ @ w - Î» * Î¼                  # gradient of smooth part
    w = w - Î· * g                      # gradient step
    w = soft_threshold(w, Î· * Îº)       # L1
    w = soft_threshold(w - w_prev, Î· * Ï„) + w_prev  # turnover cost
    w = project_box(project_linear(w, A, b), â„“, u)  # constraints
```

### 17.2 Contextual Bandit Metaâ€‘Allocator

```python
# allocate capital across strategies with riskâ€‘adjusted rewards
for t in rounds:
    x_t = build_context(features, regimes, tc_costs)
    a = argmax_j x_t[j] @ Î¸_hat[j] + Î²_t * norm(x_t[j], V_inv[j])
    deploy_strategy(a)
    r = pnl(a) - Î»_loss * max(0, -pnl(a))**p - Ïˆ * dd_breach()
    update_posterior(a, x_t[a], r)
```

### 17.3 Crash Sentinel (Complexâ€‘Systems Composite)

```python
score = z(acf1_returns) + z(var_window) + z(orderbook_imbalance) + z(turbulence_index)
if score > Î¶_hi: reduce_exposure(0.5)
if score > Î¶_kill: flatten_all(); raise_kill_switch()
```

### 17.4 Smart Order Router (SOR) Scoring

```python
for venue in venues:
    s = w1*liq(venue) - w2*impact(venue, size) - w3*fee(venue) - w4*delay(venue) + w5*fill_prob(venue)
select_top_k(venues, score=s)
```

### 17.5 Adversarial Data Validator

```python
for feat in features:
    delta = craft_corruption(feat, budget=epsilon)
    sens = metric(model(x), model(x+delta))
    if sens > tau: tripwire()  # disable trading; alert
```

---

## 18) 150â€“200 Agent Pipeline Map

**Naming convention.** `DA` (Data), `FA` (Feature), `SA` (Signal), `RA` (Regime/Risk), `PC` (Portfolio), `EX` (Execution), `GV` (Governance/Compliance), `MO` (Monitoring), `KR` (Knowledge/Registry).

**Indicative allocation (â‰ˆ 184 agents).**

- Data & Feature (â‰ˆ 70). DAâ€‘001â€¦030 (venues, assets); FAâ€‘031â€¦070 (microstructure, NLP, altâ€‘data, macro).
- Signals & Models (â‰ˆ 60). SAâ€‘071â€¦130 (momentum, meanâ€‘reversion, crossâ€‘asset spreads, macroâ€‘nowcasts, NLPâ€‘event, volatility). Multiâ€‘horizon per sleeve.
- Regime & Risk (â‰ˆ 18). RAâ€‘131â€¦148 (HMM, BOCPD, turbulence, VaR/ES, stress, crash sentinel).
- Portfolio & Allocation (â‰ˆ 12). PCâ€‘149â€¦160 (robust MV, Kellyâ€‘tempered, HRP, risk parity, capital allocator/bandit).
- Execution (â‰ˆ 12). EXâ€‘161â€¦172 (SOR, AC scheduler, limit ladder, childâ€‘order throttle, venue scorecards).
- Governance & Compliance (â‰ˆ 6). GVâ€‘173â€¦178 (restricted lists, surveillance, audit, approvals).
- Monitoring & Observability (â‰ˆ 4). MOâ€‘179â€¦182 (telemetry, drift, SLOs, anomaly detection).
- Knowledge & Registry (â‰ˆ 2). KRâ€‘183â€¦184 (model registry, artifact signing, rollout).

Each agent exposes a contracted topic on the message bus and carries riskâ€‘policy bindings (limits, standâ€‘down conditions) embedded in its signed policy.

---

## 19) Synthetic PhDâ€‘Level Identities (Specification + Generator)

### 19.1 Identity Schema (JSON)

```json
{
  "agent_id": "SA-091",
  "name": "Dr. Amina Kovalenko",
  "age": 41,
  "background": {
    "degrees": ["PhD, Statistical Learning, ETH ZÃ¼rich"],
    "domains": ["time-series", "microstructure", "causal inference"],
    "experience_years": 18,
    "notable_work": ["Liquidity-aware factor timing"],
    "certifications": ["CFA", "FRM"],
    "languages": ["English", "German", "Ukrainian"]
  },
  "skills": {
    "theory": {"stochastic_calc": 0.9, "optimization": 0.95, "econometrics": 0.92},
    "systems": {"distributed": 0.86, "low_latency": 0.8},
    "ml": {"boosting": 0.95, "bayesian": 0.9, "deep_seq": 0.85}
  },
  "personality": {"curiosity": 0.96, "prudence": 0.82, "collaboration": 0.88},
  "role": "Signal/Alpha â€” Short-horizon mean-reversion",
  "policy_bindings": ["dd_intraday<=2%", "var_limit<=1.5%"],
  "timezone": "America/New_York"
}
```

### 19.2 Identity Generator (Python)

```python
import random, json

FIRST = ["Amina","Rafael","Xinyi","Noah","Mira","Kenji","Fatima","Lukas","Ishaan","Sofia","Leila","Mateo"]
LAST = ["Kovalenko","Okoye","Tanaka","Hernandez","Schmidt","Ibrahim","Novak","Rossi","Murphy","Sato","Petrov","Zhang"]
DEGREES = [
    ("PhD, Statistical Learning, ETH ZÃ¼rich", ["time-series","econometrics","ml"]),
    ("PhD, Operations Research, MIT", ["optimization","stochastic_calc","systems"]),
    ("PhD, Computer Science, Stanford", ["deep_seq","nlp","distributed"]),
    ("PhD, Applied Math, Cambridge", ["bayesian","causal","optimization"])
]
ROLES = [
    ("DA", "Data Ingestion"), ("FA", "Feature Engineering"), ("SA", "Signal/Alpha"), ("RA", "Regime/Risk"),
    ("PC", "Portfolio"), ("EX", "Execution"), ("GV", "Governance"), ("MO", "Monitoring"), ("KR", "Registry")
]

random.seed(42)

def synth(n=200):
    out = []
    for i in range(n):
        fn = random.choice(FIRST); ln = random.choice(LAST)
        deg, domains = random.choice(DEGREES)
        prefix, role = random.choice(ROLES)
        age = random.randint(28, 68)
        exp = random.randint(max(6, age-30), max(12, age-10))
        agent_id = f"{prefix}-{i+1:03d}"
        entry = {
            "agent_id": agent_id,
            "name": f"Dr. {fn} {ln}",
            "age": age,
            "background": {
                "degrees": [deg],
                "domains": domains,
                "experience_years": exp,
                "notable_work": [],
                "certifications": [],
                "languages": ["English"]
            },
            "skills": {"theory": {}, "systems": {}, "ml": {}},
            "personality": {"curiosity": round(random.uniform(0.7,0.99),2),
                             "prudence": round(random.uniform(0.6,0.95),2),
                             "collaboration": round(random.uniform(0.6,0.95),2)},
            "role": role,
            "policy_bindings": [],
            "timezone": "UTC"
        }
        out.append(entry)
    return out

# Example: print(json.dumps(synth(10), indent=2))
```

### 19.3 Sample (5 Identities)

```json
[
  {"agent_id":"SA-001","name":"Dr. Xinyi Zhang","age":53,"role":"Signal/Alpha","background":{"degrees":["PhD, Operations Research, MIT"],"domains":["optimization","stochastic_calc","systems"],"experience_years":34}},
  {"agent_id":"FA-002","name":"Dr. Noah Rossi","age":44,"role":"Feature Engineering","background":{"degrees":["PhD, Computer Science, Stanford"],"domains":["deep_seq","nlp","distributed"],"experience_years":31}},
  {"agent_id":"RA-003","name":"Dr. Leila Sato","age":39,"role":"Regime/Risk","background":{"degrees":["PhD, Applied Math, Cambridge"],"domains":["bayesian","causal","optimization"],"experience_years":27}},
  {"agent_id":"EX-004","name":"Dr. Rafael Petrov","age":36,"role":"Execution","background":{"degrees":["PhD, Operations Research, MIT"],"domains":["optimization","stochastic_calc","systems"],"experience_years":24}},
  {"agent_id":"GV-005","name":"Dr. Mira Murphy","age":61,"role":"Governance","background":{"degrees":["PhD, Statistical Learning, ETH ZÃ¼rich"],"domains":["time-series","econometrics","ml"],"experience_years":41}}
]
```

---

## 20) Governance & Safety for Synthetic Agents

- Provenance: all identities are synthetic; no realâ€‘person data or likenesses are used.
- Bias controls: sample names and attributes from balanced pools; enforce demographicâ€‘diversity constraints.
- Access control: identities map to leastâ€‘privilege roles; liveâ€‘trading permissions require signed policies and approvals.
- Accountability: every agent attaches a policy version, hash, and audit trail to its actions.

---

## 21) Scaleâ€‘Out Implementation Roadmap (24 â†’ 200 Agents)

1. Contract unification: freeze event schemas; implement validation and golden datasets.
2. Feature & model factories: autoâ€‘codegen from spec files; unit tests + backtest harness.
3. Risk & regime layer: deploy HMM/BOCPD/turbulence; wire crash sentinel to the kill switch.
4. Execution excellence: roll out AC scheduler, SOR scorecards, limitâ€‘ladder A/B tests; close the TCA loop.
5. Metaâ€‘allocation: contextual bandit with CVaRâ€‘penalized reward; capital reallocator.
6. Governance: approvals workflow, artifact signing (HSM), shadow â†’ canary â†’ full automation.
7. Observability: drift dashboards, SPA/deflatedâ€‘Sharpe analytics, incidentâ€‘response runbooks.

**Deliverable:** A production blueprint that scales agents horizontally with mathematically grounded policies and fully governed rollouts.

---

## 22) Production Code Modules (Ready-to-Run)

> **Notes.**
>
> - All modules are pure Python with optional `cvxpy` acceleration where noted.
> - Replace stubs (e.g., broker adapters) with platform specifics. Add logging/auth per your standards.

### 22.1 Proximal Robust Meanâ€“Variance Optimizer (with L1, Turnover, Box & Linear Constraints)

```python
# production/math/optim/prox_mvo.py
from __future__ import annotations
import math
import numpy as np
from dataclasses import dataclass
from typing import Optional, Tuple

try:
    import cvxpy as cp
    _HAS_CVXPY = True
except Exception:
    _HAS_CVXPY = False

Array = np.ndarray

@dataclass
class MVOCfg:
    step_size: float = 1e-2          # initial step size for backtracking
    backtrack_beta: float = 0.6      # step-size shrink factor (0,1)
    backtrack_c: float = 1e-4        # Armijo constant
    max_iter: int = 2000
    tol: float = 1e-6
    use_cvxpy_projection: bool = True

@dataclass
class MVOProblem:
    mu: Array                # expected returns, shape (n,)
    Sigma: Array             # covariance, shape (n,n)
    w_prev: Array            # previous weights, shape (n,)
    lam: float               # mean-variance trade-off (lambda)
    tau: float               # L1 turnover penalty weight
    kappa: float             # L1 weight penalty
    A: Optional[Array] = None    # linear constraints A w <= b
    b: Optional[Array] = None
    lower: Optional[Array] = None # box lower bound
    upper: Optional[Array] = None # box upper bound


def soft_threshold(x: Array, thr: float) -> Array:
    return np.sign(x) * np.maximum(np.abs(x) - thr, 0.0)


def project_box(w: Array, lower: Optional[Array], upper: Optional[Array]) -> Array:
    if lower is not None:
        w = np.maximum(w, lower)
    if upper is not None:
        w = np.minimum(w, upper)
    return w


def project_linear(w: Array, A: Optional[Array], b: Optional[Array]) -> Array:
    """Project w onto {A w <= b} in Euclidean norm. Requires cvxpy if constraints present."""
    if A is None or b is None:
        return w
    if not _HAS_CVXPY:
        # Fallback: return as-is with a warning in comments
        # In production, enforce presence of cvxpy or replace with custom QP projector
        return w
    x = cp.Variable(w.shape[0])
    obj = cp.Minimize(0.5 * cp.sum_squares(x - w))
    cons = [A @ x <= b]
    prob = cp.Problem(obj, cons)
    prob.solve(solver=cp.OSQP, eps_abs=1e-7, eps_rel=1e-7, verbose=False)
    return np.asarray(x.value).reshape(-1)


def objective(w: Array, P: MVOProblem) -> float:
    quad = 0.5 * float(w @ P.Sigma @ w)
    mean_term = - P.lam * float(P.mu @ w)
    l1_pos = P.kappa * float(np.sum(np.abs(w)))
    l1_turn = P.tau * float(np.sum(np.abs(w - P.w_prev)))
    return quad + mean_term + l1_pos + l1_turn


def prox_mvo(P: MVOProblem, cfg: MVOCfg = MVOCfg()) -> Tuple[Array, dict]:
    """Proximal gradient with backtracking and constraint projection.
    - Smooth part: 0.5 w^T Sigma w - lam mu^T w
    - Non-smooth: kappa ||w||_1 + tau ||w - w_prev||_1 + I_{Aw<=b, box}
    """
    n = P.mu.shape[0]
    w = P.w_prev.copy()
    t = cfg.step_size

    def grad(w_: Array) -> Array:
        return P.Sigma @ w_ - P.lam * P.mu

    hist = {"obj": [], "step": [], "gap": []}

    for it in range(cfg.max_iter):
        g = grad(w)
        # gradient step
        w_bar = w - t * g
        # proximal on L1 (weights)
        w_bar = soft_threshold(w_bar, t * P.kappa)
        # proximal on turnover L1 -> soft-threshold around w_prev
        w_bar = w.Prev + soft_threshold(w_bar - P.w_prev, t * P.tau)  # type: ignore
        # box projection
        w_bar = project_box(w_bar, P.lower, P.upper)
        # linear projection
        if cfg.use_cvxpy_projection and P.A is not None:
            w_bar = project_linear(w_bar, P.A, P.b)

        # backtracking Armijo
        f_w = objective(w, P)
        f_bar = objective(w_bar, P)
        # simple sufficient decrease check
        lin_approx = f_w + g @ (w_bar - w) + (1.0 / (2.0 * t)) * np.linalg.norm(w_bar - w) ** 2
        bt = 0
        while f_bar > lin_approx and bt < 20:
            t *= cfg.backtrack_beta
            w_bar = w - t * g
            w_bar = soft_threshold(w_bar, t * P.kappa)
            w_bar = P.w_prev + soft_threshold(w_bar - P.w_prev, t * P.tau)
            w_bar = project_box(w_bar, P.lower, P.upper)
            if cfg.use_cvxpy_projection and P.A is not None:
                w_bar = project_linear(w_bar, P.A, P.b)
            f_bar = objective(w_bar, P)
            lin_approx = f_w + g @ (w_bar - w) + (1.0 / (2.0 * t)) * np.linalg.norm(w_bar - w) ** 2
            bt += 1

        gap = np.linalg.norm(w_bar - w, ord=np.inf)
        w = w_bar
        hist["obj"].append(f_bar)
        hist["step"].append(t)
        hist["gap"].append(gap)
        if gap < cfg.tol:
            break

    return w, {"iters": it + 1, **hist}


# Optional exact solver using cvxpy for validation or small n

def cvxpy_mvo(P: MVOProblem) -> Array:
    if not _HAS_CVXPY:
        raise RuntimeError("cvxpy not available")
    n = P.mu.shape[0]
    w = cp.Variable(n)
    obj = 0.5 * cp.quad_form(w, P.Sigma) - P.lam * P.mu @ w \
          + P.kappa * cp.norm1(w) + P.tau * cp.norm1(w - P.w_prev)
    cons = []
    if P.lower is not None:
        cons.append(w >= P.lower)
    if P.upper is not None:
        cons.append(w <= P.upper)
    if P.A is not None and P.b is not None:
        cons.append(P.A @ w <= P.b)
    prob = cp.Problem(cp.Minimize(obj), cons)
    prob.solve(solver=cp.OSQP, eps_abs=1e-7, eps_rel=1e-7, verbose=False)
    return np.asarray(w.value).reshape(-1)
```

**Usage (sketch):**

```python
import numpy as np
from production.math.optim.prox_mvo import MVOProblem, MVOCfg, prox_mvo

n = 50
rng = np.random.default_rng(0)
Sigma = 0.1*np.eye(n) + 0.9*rng.random((n,n)); Sigma = (Sigma+Sigma.T)/2 + 1e-3*np.eye(n)
mu = rng.normal(0.001, 0.01, size=n)
w_prev = np.zeros(n)
P = MVOProblem(mu=mu, Sigma=Sigma, w_prev=w_prev, lam=2.0, tau=0.001, kappa=0.0005,
               lower=np.full(n,-0.05), upper=np.full(n,0.05))
w, info = prox_mvo(P)
```

---

### 22.2 Almgrenâ€“Chriss Scheduler (QP backend + closed-form for constant coefficients)

```python
# production/execution/ac_scheduler.py
from __future__ import annotations
import numpy as np
from dataclasses import dataclass
from typing import Optional, Dict

try:
    import cvxpy as cp
    _HAS_CVXPY = True
except Exception:
    _HAS_CVXPY = False

@dataclass
class ACParams:
    x0: float                 # initial inventory (shares)
    xN: float                 # terminal inventory (target shares)
    N: int                    # number of slices
    dt: float                 # time per slice
    sigma: float              # volatility per sqrt(time)
    eta: float                # temporary impact coef (cost ~ eta * v_k^2)
    epsilon: float = 0.0      # fixed cost per share (half-spread)
    gamma: float = 0.0        # permanent impact per share traded
    phi: float = 1e-6         # risk aversion (variance weight)


def schedule_closed_form(p: ACParams) -> Dict[str, np.ndarray]:
    """Closed-form near-exponential schedule for constant coefficients (gamma=0).
    Returns dict with path x_k and child sizes v_k = -(x_k - x_{k-1})."""
    assert p.N >= 2
    x = np.zeros(p.N+1)
    x[0] = p.x0; x[-1] = p.xN
    # kappa from AC continuous-time approximation
    # kappa^2 = phi * sigma^2 / (eta)
    kappa = np.sqrt(max(1e-16, p.phi * (p.sigma**2) / max(1e-16, p.eta)))
    # near-exponential decay towards xN
    # normalize so that x_N = xN exactly
    exp_terms = np.exp(-kappa * np.arange(0, p.N+1))
    # solve a,b for boundary conditions: x_k = a * exp(-kappa k) + b
    # x_0 = a + b = x0; x_N = a*exp(-kappa N) + b = xN
    eN = np.exp(-kappa * p.N)
    a = (p.x0 - p.xN) / (1.0 - eN)
    b = p.x0 - a
    for k in range(1, p.N):
        x[k] = a * np.exp(-kappa * k) + b
    v = -(x[1:] - x[:-1])  # positive = sell
    return {"x": x, "v": v, "kappa": kappa}


def schedule_qp(p: ACParams) -> Dict[str, np.ndarray]:
    """Exact discrete QP using cvxpy: minimize sum(eta v_k^2 + epsilon |v_k|) + phi Var(C).
    State: x_k = x_{k-1} - v_k. Enforce x_0,x_N boundary conditions."""
    if not _HAS_CVXPY:
        return schedule_closed_form(p)
    N = p.N
    v = cp.Variable(N)   # child sizes per slice
    x = cp.Variable(N+1)
    cons = [x[0] == p.x0, x[N] == p.xN]
    for k in range(1, N+1):
        cons += [x[k] == x[k-1] - v[k-1]]
    temp_cost = cp.sum(p.eta * cp.square(v) + p.epsilon * cp.abs(v))
    # variance term ~ phi * sigma^2 * sum_{k} x_k^2 * dt
    var_term = p.phi * (p.sigma**2) * p.dt * cp.sum_squares(x)
    # permanent impact (linear in cumulative volume): add gamma * sum v_k * x_{k-1} approx
    perm_approx = p.gamma * cp.sum(cp.multiply(v, x[:-1]))
    obj = cp.Minimize(temp_cost + var_term + perm_approx)
    prob = cp.Problem(obj, cons)
    prob.solve(solver=cp.OSQP, eps_abs=1e-8, eps_rel=1e-8, verbose=False)
    return {"x": np.array(x.value).reshape(-1), "v": np.array(v.value).reshape(-1)}
```

**Usage (sketch):**

```python
from production.execution.ac_scheduler import ACParams, schedule_qp
p = ACParams(x0=1_000_000, xN=0, N=20, dt=60.0, sigma=0.02, eta=1e-6, epsilon=0.0001, gamma=0.0, phi=1e-6)
out = schedule_qp(p)
```

---

### 22.3 Contextual LinUCB Metaâ€‘Allocator with CVaR Penalty

```python
# production/alloc/linucb_allocator.py
from __future__ import annotations
import numpy as np
from dataclasses import dataclass
from typing import Dict, List, Tuple

@dataclass
class LinUCBConfig:
    alpha_reg: float = 1.0           # ridge regularization
    beta_ucb: float = 1.5            # exploration weight
    max_alloc: float = 0.25          # per-arm cap
    min_alloc: float = 0.0           # per-arm floor
    cvar_q: float = 0.05             # CVaR quantile (e.g., 5%)
    cvar_lambda: float = 0.1         # penalty weight on CVaR (larger -> more conservative)

class LinUCBAllocator:
    def __init__(self, n_arms: int, n_features: int, cfg: LinUCBConfig = LinUCBConfig()):
        self.cfg = cfg
        self.n_arms = n_arms
        self.n_features = n_features
        self.A = [self.cfg.alpha_reg * np.eye(n_features) for _ in range(n_arms)]
        self.b = [np.zeros((n_features,)) for _ in range(n_arms)]
        self.rets: List[List[float]] = [[] for _ in range(n_arms)]

    def _theta(self, j: int) -> np.ndarray:
        return np.linalg.solve(self.A[j], self.b[j])

    def score(self, contexts: np.ndarray) -> np.ndarray:
        """contexts shape: (n_arms, n_features). Returns UCB scores minus CVaR penalty."""
        scores = np.zeros(self.n_arms)
        for j in range(self.n_arms):
            x = contexts[j]
            A_inv = np.linalg.inv(self.A[j])
            theta = A_inv @ self.b[j]
            mean = float(x @ theta)
            ucb = self.cfg.beta_ucb * math.sqrt(x @ A_inv @ x)
            # empirical CVaR penalty (if enough samples)
            penalty = 0.0
            if len(self.rets[j]) >= 20:
                arr = np.sort(np.array(self.rets[j]))
                k = max(1, int(self.cfg.cvar_q * len(arr)))
                cva
```

---
Provide project context and coding guidelines that AI should follow when generating code, answering questions, or reviewing changes.